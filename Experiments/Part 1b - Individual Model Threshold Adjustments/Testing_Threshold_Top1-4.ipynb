{"cells":[{"cell_type":"markdown","metadata":{"id":"CKeVGxZ5GG6o"},"source":["# Import needed modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBYLqPKdUB5s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691996187010,"user_tz":-480,"elapsed":2563,"user":{"displayName":"Thesis TempF","userId":"15864590997921893499"}},"outputId":"a61c9af1-bc2b-4edd-a468-781794d26651"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["model1_name = 'ConvNeXtTiny'\n","model2_name = 'MobileNetV2'\n","model3_name = 'InceptionV3'\n","model4_name = 'DenseNet121'\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeMcAy_5GG6s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691996187012,"user_tz":-480,"elapsed":23,"user":{"displayName":"Thesis TempF","userId":"15864590997921893499"}},"outputId":"a792195f-e17b-4910-846c-9e44d7906ac1"},"outputs":[{"output_type":"stream","name":"stdout","text":["modules loaded\n"]}],"source":["# import system libs\n","import os\n","import time\n","import shutil\n","import pathlib\n","import itertools\n","\n","# import data handling tools\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","\n","# import Deep learning Libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n","from tensorflow.keras import regularizers\n","\n","# Ignore Warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print ('modules loaded')"]},{"cell_type":"markdown","metadata":{"id":"SA_gwvwnGG6v"},"source":["# Create needed functions"]},{"cell_type":"markdown","metadata":{"id":"JQdhl_CRGG6v"},"source":["#### **Function to create data frame**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2nDmYaAabWE"},"outputs":[],"source":["# Generate data paths with labels\n","def define_paths(dir):\n","    filepaths = []\n","    labels = []\n","\n","    folds = os.listdir(dir)\n","    for fold in folds:\n","        foldpath = os.path.join(dir, fold)\n","        filelist = os.listdir(foldpath)\n","\n","        for fold_ in filelist:\n","            foldpath_ = os.path.join(foldpath, fold_)\n","            filelist_ = os.listdir(foldpath_)\n","\n","            for file_ in filelist_:\n","                fpath = os.path.join(foldpath_, file_)\n","                filepaths.append(fpath)\n","                labels.append(fold_)\n","\n","    return filepaths, labels\n","\n","\n","# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )\n","def define_df(files, classes):\n","    Fseries = pd.Series(files, name= 'filepaths')\n","    Lseries = pd.Series(classes, name='labels')\n","    return pd.concat([Fseries, Lseries], axis= 1)\n","\n","\n","# Function that create dataframe for train, validation, and test data\n","def create_df(data_dir):\n","\n","    # train dataframe\n","    files, classes = define_paths(data_dir[0])\n","    df = define_df(files, classes)\n","\n","    strat = df['labels']\n","    train_df, valid_df = train_test_split(df, train_size=0.85, shuffle=True, random_state=123, stratify=strat)\n","\n","    # test dataframe\n","    files, classes = define_paths(data_dir[1])\n","    test_df = define_df(files, classes)\n","\n","    return train_df, valid_df, test_df"]},{"cell_type":"markdown","metadata":{"id":"JZaHdeFxGG6x"},"source":["#### Function to generate images from dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLL8hHQcGG6x"},"outputs":[],"source":["def create_model_data (train_df, valid_df, test_df, batch_size):\n","    '''\n","    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n","    Image data generator converts images into tensors. '''\n","\n","\n","    # define model parameters\n","    img_size = (224, 224)\n","    channels = 3 # either BGR or Grayscale\n","    color = 'rgb'\n","    img_shape = (img_size[0], img_size[1], channels)\n","\n","    # Recommended : use custom function for test data batch size, else we can use normal batch size.\n","    ts_length = len(test_df)\n","    test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","    test_steps = ts_length // test_batch_size\n","\n","    # This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n","    def scalar(img):\n","        return img\n","\n","    tr_gen = ImageDataGenerator(\n","      preprocessing_function= scalar,\n","      rotation_range=50,\n","      horizontal_flip=True,\n","      vertical_flip=True\n","    )\n","\n","    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n","\n","    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= True, batch_size= batch_size)\n","\n","    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= True, batch_size= batch_size)\n","\n","    # Note: we will use custom test_batch_size, and make shuffle= false\n","    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= False, batch_size= test_batch_size)\n","\n","    return train_gen, valid_gen, test_gen"]},{"cell_type":"markdown","metadata":{"id":"57eDFl3oGG65"},"source":["# **Model Structure**"]},{"cell_type":"markdown","metadata":{"id":"2GHNMVrhGG65"},"source":["#### **Start Reading Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWfxfQEVabWS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691996189639,"user_tz":-480,"elapsed":2640,"user":{"displayName":"Thesis TempF","userId":"15864590997921893499"}},"outputId":"32c61aca-450b-48bd-f3d5-ed590a613dd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6830 validated image filenames belonging to 2 classes.\n","Found 1205 validated image filenames belonging to 2 classes.\n","Found 4522 validated image filenames belonging to 2 classes.\n"]}],"source":["data_dir = ['/content/drive/MyDrive/C-NMC_Leukemia/training_data','/content/drive/MyDrive/C-NMC_Leukemia/validation_data']\n","\n","try:\n","    # Get splitted data\n","    train_df, valid_df, test_df = create_df(data_dir)\n","\n","    # Get Generators\n","    batch_size = 40\n","    train_gen, valid_gen, test_gen = create_model_data(train_df, valid_df, test_df, batch_size)\n","\n","except:\n","    print('Invalid Input')"]},{"cell_type":"markdown","metadata":{"id":"3wvOKjeRGG65"},"source":["#### **Generic Model Creation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDT4CV15abWT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691996334503,"user_tz":-480,"elapsed":23190,"user":{"displayName":"Thesis TempF","userId":"15864590997921893499"}},"outputId":"35381794-0320-4a6b-d9e2-ba3f68515333"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," convnext_tiny (Functional)  (None, 768)               27820128  \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 768)              3072      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_4 (Dense)             (None, 256)               196864    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 28,020,578\n","Trainable params: 28,019,042\n","Non-trainable params: 1,536\n","_________________________________________________________________\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9406464/9406464 [==============================] - 0s 0us/step\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n"," ional)                                                          \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 1280)             5120      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               327936    \n","                                                                 \n"," dropout_3 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 2,591,554\n","Trainable params: 2,554,882\n","Non-trainable params: 36,672\n","_________________________________________________________________\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 0s 0us/step\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_v3 (Functional)   (None, 2048)              21802784  \n","                                                                 \n"," batch_normalization_98 (Bat  (None, 2048)             8192      \n"," chNormalization)                                                \n","                                                                 \n"," dense_8 (Dense)             (None, 256)               524544    \n","                                                                 \n"," dropout_4 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 22,336,034\n","Trainable params: 22,297,506\n","Non-trainable params: 38,528\n","_________________________________________________________________\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29084464/29084464 [==============================] - 0s 0us/step\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," densenet121 (Functional)    (None, 1024)              7037504   \n","                                                                 \n"," batch_normalization_99 (Bat  (None, 1024)             4096      \n"," chNormalization)                                                \n","                                                                 \n"," dense_10 (Dense)            (None, 256)               262400    \n","                                                                 \n"," dropout_5 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_11 (Dense)            (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 7,304,514\n","Trainable params: 7,218,818\n","Non-trainable params: 85,696\n","_________________________________________________________________\n"]}],"source":["# Create Model Structure\n","img_size = (224, 224)\n","channels = 3\n","img_shape = (img_size[0], img_size[1], channels)\n","class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n","\n","# MODEL 1\n","base_model = tf.keras.applications.ConvNeXtTiny(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n","model1 = Sequential([\n","    base_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","model1.compile(Adamax(learning_rate= 0.0012), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","model1.load_weights(f'/content/drive/MyDrive/Models/ALL-final-{model1_name}-weights.h5')\n","model1.summary()\n","\n","# MODEL 2\n","base_model = tf.keras.applications.MobileNetV2(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n","model2 = Sequential([\n","    base_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","model2.compile(Adamax(learning_rate= 0.0012), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","model2.load_weights(f'/content/drive/MyDrive/Models/ALL-final-{model2_name}-weights.h5')\n","model2.summary()\n","\n","# MODEL 3\n","base_model = tf.keras.applications.InceptionV3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n","model3 = Sequential([\n","    base_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","model3.compile(Adamax(learning_rate= 0.0012), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","model3.load_weights(f'/content/drive/MyDrive/Models/ALL-final-{model3_name}-weights.h5')\n","model3.summary()\n","\n","# MODEL 4\n","base_model = tf.keras.applications.DenseNet121(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n","model4 = Sequential([\n","    base_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","model4.compile(Adamax(learning_rate= 0.0012), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","model4.load_weights(f'/content/drive/MyDrive/Models/ALL-final-{model4_name}-weights.h5')\n","model4.summary()"]},{"cell_type":"markdown","metadata":{"id":"MySXhfAJGG68"},"source":["# **Evaluate model**"]},{"cell_type":"markdown","metadata":{"id":"4l-DABtFGG68"},"source":["# **Get Predictions**"]},{"cell_type":"code","source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size"],"metadata":{"id":"avbE3DBTvNEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Tasks per fold:**\n","\n","1. Make predictions\n","2. Adjust thresholds and produce classification report for each threshold pair\n","3. Get best threshold levels for each result metric\n","4. Display adjusted confusion matrix and metrics with improvement\n","5. Append top [chosen metric=> Weighted F1-Score] to the scores list"],"metadata":{"id":"Et92Q-YwjHFf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1V-seI9iihJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"299237d6-db06-4918-a9ca-4b6c41987edd","executionInfo":{"status":"ok","timestamp":1691998516883,"user_tz":-480,"elapsed":9658,"user":{"displayName":"Thesis TempF","userId":"15864590997921893499"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["**********************************\n","Model # 1\n","**********************************\n","119/119 [==============================] - 35s 289ms/step - loss: 0.2059 - accuracy: 0.9489\n","--------------------\n","Original threshold\n","Test Loss:  0.20593611896038055\n","Test Accuracy:  0.9489164352416992\n","\n","Confusion matrix:\n","[[2998   43]\n"," [ 188 1293]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9410    0.9859    0.9629      3041\n","         hem     0.9678    0.8731    0.9180      1481\n","\n","    accuracy                         0.9489      4522\n","   macro avg     0.9544    0.9295    0.9405      4522\n","weighted avg     0.9498    0.9489    0.9482      4522\n","\n","\n","For the threshold adjustments on test set predictions for Model 1\n","Best accuracy           - threshold [0.7,0.3] -> 95.4%\n","Best ALL precision      - threshold [0.9,0.1] -> 97.23%\n","Best weighted precision - threshold [0.7,0.3] -> 95.39%\n","Best ALL recall         - threshold [0.5,0.5] -> 98.59%\n","Best weighted recall    - threshold [0.7,0.3] -> 95.4%\n","Best ALL f1-score       - threshold [0.7,0.3] -> 96.62%\n","Best weighted f1-score  - threshold [0.7,0.3] -> 95.37%\n","\n","Threshold used for adjusted predictions is: [ 0.7 , 0.3 ]\n","\n","Confusion matrix:\n","[[2972   69]\n"," [ 141 1340]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9547    0.9773    0.9659      3041\n","         hem     0.9510    0.9048    0.9273      1481\n","\n","    accuracy                         0.9536      4522\n","   macro avg     0.9529    0.9411    0.9466      4522\n","weighted avg     0.9535    0.9536    0.9533      4522\n","\n","Change in accuracy           : 0.509 %\n","Change in ALL precision      : 1.433 %\n","Change in weighted precision : 0.416 %\n","Change in ALL recall         : -0.855 %\n","Change in weighted recall    : 0.509 %\n","Change in ALL F1-score       : 0.329 %\n","Change in weighted F1-score  : 0.551 %\n","\n","**********************************\n","Model # 2\n","**********************************\n","119/119 [==============================] - 16s 136ms/step - loss: 0.2595 - accuracy: 0.9264\n","--------------------\n","Original threshold\n","Test Loss:  0.25952601432800293\n","Test Accuracy:  0.926360011100769\n","\n","Confusion matrix:\n","[[2936  105]\n"," [ 228 1253]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9279    0.9655    0.9463      3041\n","         hem     0.9227    0.8460    0.8827      1481\n","\n","    accuracy                         0.9264      4522\n","   macro avg     0.9253    0.9058    0.9145      4522\n","weighted avg     0.9262    0.9264    0.9255      4522\n","\n","\n","For the threshold adjustments on test set predictions for Model 2\n","Best accuracy           - threshold [0.63,0.37] -> 92.86%\n","Best ALL precision      - threshold [0.9,0.1] -> 96.02%\n","Best weighted precision - threshold [0.68,0.32] -> 92.84%\n","Best ALL recall         - threshold [0.5,0.5] -> 96.55%\n","Best weighted recall    - threshold [0.63,0.37] -> 92.86%\n","Best ALL f1-score       - threshold [0.63,0.37] -> 94.74%\n","Best weighted f1-score  - threshold [0.68,0.32] -> 92.84%\n","\n","Threshold used for adjusted predictions is: [ 0.68 , 0.32 ]\n","\n","Confusion matrix:\n","[[2890  151]\n"," [ 172 1309]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9438    0.9503    0.9471      3041\n","         hem     0.8966    0.8839    0.8902      1481\n","\n","    accuracy                         0.9286      4522\n","   macro avg     0.9202    0.9171    0.9186      4522\n","weighted avg     0.9284    0.9286    0.9284      4522\n","\n","Change in accuracy           : 0.221 %\n","Change in ALL precision      : 1.589 %\n","Change in weighted precision : 0.214 %\n","Change in ALL recall         : -1.513 %\n","Change in weighted recall    : 0.221 %\n","Change in ALL F1-score       : 0.074 %\n","Change in weighted F1-score  : 0.294 %\n","\n","**********************************\n","Model # 3\n","**********************************\n","119/119 [==============================] - 17s 143ms/step - loss: 0.2734 - accuracy: 0.9177\n","--------------------\n","Original threshold\n","Test Loss:  0.2734268605709076\n","Test Accuracy:  0.9177355170249939\n","\n","Confusion matrix:\n","[[2986   55]\n"," [ 317 1164]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9040    0.9819    0.9414      3041\n","         hem     0.9549    0.7860    0.8622      1481\n","\n","    accuracy                         0.9177      4522\n","   macro avg     0.9295    0.8839    0.9018      4522\n","weighted avg     0.9207    0.9177    0.9154      4522\n","\n","\n","For the threshold adjustments on test set predictions for Model 3\n","Best accuracy           - threshold [0.72,0.28] -> 92.66%\n","Best ALL precision      - threshold [0.9,0.1] -> 96.07%\n","Best weighted precision - threshold [0.72,0.28] -> 92.61%\n","Best ALL recall         - threshold [0.5,0.5] -> 98.19%\n","Best weighted recall    - threshold [0.72,0.28] -> 92.66%\n","Best ALL f1-score       - threshold [0.72,0.28] -> 94.61%\n","Best weighted f1-score  - threshold [0.72,0.28] -> 92.61%\n","\n","Threshold used for adjusted predictions is: [ 0.72 , 0.28 ]\n","\n","Confusion matrix:\n","[[2912  129]\n"," [ 205 1276]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9342    0.9576    0.9458      3041\n","         hem     0.9082    0.8616    0.8843      1481\n","\n","    accuracy                         0.9261      4522\n","   macro avg     0.9212    0.9096    0.9150      4522\n","weighted avg     0.9257    0.9261    0.9256      4522\n","\n","Change in accuracy           : 0.885 %\n","Change in ALL precision      : 3.108 %\n","Change in weighted precision : 0.546 %\n","Change in ALL recall         : -2.466 %\n","Change in weighted recall    : 0.885 %\n","Change in ALL F1-score       : 0.469 %\n","Change in weighted F1-score  : 1.065 %\n","\n","**********************************\n","Model # 4\n","**********************************\n","119/119 [==============================] - 18s 153ms/step - loss: 0.3098 - accuracy: 0.9069\n","--------------------\n","Original threshold\n","Test Loss:  0.3097779452800751\n","Test Accuracy:  0.906899631023407\n","\n","Confusion matrix:\n","[[2949   92]\n"," [ 329 1152]]\n","              precision    recall  f1-score   support\n","\n","         all     0.8996    0.9697    0.9334      3041\n","         hem     0.9260    0.7779    0.8455      1481\n","\n","    accuracy                         0.9069      4522\n","   macro avg     0.9128    0.8738    0.8894      4522\n","weighted avg     0.9083    0.9069    0.9046      4522\n","\n","\n","For the threshold adjustments on test set predictions for Model 4\n","Best accuracy           - threshold [0.6,0.4] -> 91.22%\n","Best ALL precision      - threshold [0.9,0.1] -> 96.56%\n","Best weighted precision - threshold [0.6,0.4] -> 91.2%\n","Best ALL recall         - threshold [0.5,0.5] -> 96.97%\n","Best weighted recall    - threshold [0.6,0.4] -> 91.22%\n","Best ALL f1-score       - threshold [0.6,0.4] -> 93.63%\n","Best weighted f1-score  - threshold [0.7,0.3] -> 91.11%\n","\n","Threshold used for adjusted predictions is: [ 0.7 , 0.3 ]\n","\n","Confusion matrix:\n","[[2859  182]\n"," [ 221 1260]]\n","              precision    recall  f1-score   support\n","\n","         all     0.9282    0.9402    0.9342      3041\n","         hem     0.8738    0.8508    0.8621      1481\n","\n","    accuracy                         0.9109      4522\n","   macro avg     0.9010    0.8955    0.8981      4522\n","weighted avg     0.9104    0.9109    0.9106      4522\n","\n","Change in accuracy           : 0.442 %\n","Change in ALL precision      : 3.005 %\n","Change in weighted precision : 0.265 %\n","Change in ALL recall         : -3.058 %\n","Change in weighted recall    : 0.442 %\n","Change in ALL F1-score       : 0.103 %\n","Change in weighted F1-score  : 0.648 %\n","\n"]}],"source":["best_scores = []\n","y = 1\n","\n","for model in [model1, model2, model3, model4]:\n","  print('**********************************')\n","  print(f'Model # {y}')\n","  print('**********************************')\n","\n","  test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","  print('-' * 20)\n","  print('Original threshold')\n","  print(\"Test Loss: \", test_score[0])\n","  print(\"Test Accuracy: \", test_score[1])\n","\n","  # make predictions\n","  y_pred_probs = model.predict_generator(test_gen)\n","  y_pred_original = np.argmax(y_pred_probs, axis=1)\n","  cm = confusion_matrix(test_gen.classes, y_pred_original)\n","  print()\n","  print('Confusion matrix:')\n","  print(cm)\n","  print(classification_report(test_gen.classes, y_pred_original, target_names= classes, digits= 4))\n","\n","  # experimenting thresholds\n","  acc_list = []\n","  pre_list = []\n","  w_pre_list = []\n","  rec_list = []\n","  w_rec_list = []\n","  f1_list = []\n","  w_f1_list = []\n","\n","  thresholds = [0.5,0.5]\n","\n","  for x in range(81):\n","    thresholds[0] = 0.5 + x*0.005\n","    thresholds[1] = 0.5 - x*0.005\n","    y_pred_adjusted = (y_pred_probs >= thresholds).astype(int) # Applying the adjusted thresholds for each class\n","    y_pred_adjusted = np.argmax(y_pred_adjusted, axis=1)\n","\n","    acc_list.append(accuracy_score(test_gen.classes, y_pred_adjusted))\n","    pre_list.append( precision_score(test_gen.classes, y_pred_adjusted, pos_label= 0))\n","    w_pre_list.append( precision_score(test_gen.classes, y_pred_adjusted, average='weighted'))\n","    rec_list.append(recall_score(test_gen.classes, y_pred_adjusted, pos_label= 0))\n","    w_rec_list.append(recall_score(test_gen.classes, y_pred_adjusted, average='weighted'))\n","    f1_list.append(f1_score(test_gen.classes, y_pred_adjusted, pos_label= 0))\n","    w_f1_list.append(f1_score(test_gen.classes, y_pred_adjusted, average='weighted'))\n","\n","  # results\n","  best_acc_ndx = np.argmax(np.array(acc_list))\n","  best_pre_ndx = np.argmax(np.array(pre_list))\n","  best_w_pre_ndx = np.argmax(np.array(w_pre_list))\n","  best_rec_ndx = np.argmax(np.array(rec_list))\n","  best_w_rec_ndx = np.argmax(np.array(w_rec_list))\n","  best_f1_ndx = np.argmax(np.array(f1_list))\n","  best_w_f1_ndx = np.argmax(np.array(w_f1_list))\n","\n","  print()\n","  print(f'For the threshold adjustments on test set predictions for Model {y}')\n","  print(f'Best accuracy           - threshold [{round(0.5+0.005*best_acc_ndx,2)},{round(0.5-0.005*best_acc_ndx,2)}] -> {round(acc_list[best_acc_ndx]*100,2)}%')\n","  print(f'Best ALL precision      - threshold [{round(0.5+0.005*best_pre_ndx,2)},{round(0.5-0.005*best_pre_ndx,2)}] -> {round(pre_list[best_pre_ndx]*100,2)}%')\n","  print(f'Best weighted precision - threshold [{round(0.5+0.005*best_w_pre_ndx,2)},{round(0.5-0.005*best_w_pre_ndx,2)}] -> {round(w_pre_list[best_w_pre_ndx]*100,2)}%')\n","  print(f'Best ALL recall         - threshold [{round(0.5+0.005*best_rec_ndx,2)},{round(0.5-0.005*best_rec_ndx,2)}] -> {round(rec_list[best_rec_ndx]*100,2)}%')\n","  print(f'Best weighted recall    - threshold [{round(0.5+0.005*best_w_rec_ndx,2)},{round(0.5-0.005*best_w_rec_ndx,2)}] -> {round(w_rec_list[best_w_rec_ndx]*100,2)}%')\n","  print(f'Best ALL f1-score       - threshold [{round(0.5+0.005*best_f1_ndx,2)},{round(0.5-0.005*best_f1_ndx,2)}] -> {round(f1_list[best_f1_ndx]*100,2)}%')\n","  print(f'Best weighted f1-score  - threshold [{round(0.5+0.005*best_w_f1_ndx,2)},{round(0.5-0.005*best_w_f1_ndx,2)}] -> {round(w_f1_list[best_w_f1_ndx]*100,2)}%')\n","  print()\n","\n","  # Apply the chosen threshold\n","  best_ndx = best_w_f1_ndx # Here we use Weighted F1 score. Change here if you want a different criteria\n","\n","  thresholds = [round(0.5+0.005*best_ndx,2),round(0.5-0.005*best_ndx,2)]\n","  y_pred_adjusted = (y_pred_probs >= thresholds).astype(int) # Applying the adjusted thresholds for each class\n","  y_pred_adjusted = np.argmax(y_pred_adjusted, axis=1) # Getting the updated predictions\n","  cm = confusion_matrix(test_gen.classes, y_pred_adjusted)\n","\n","  #print adjusted metrics\n","  print(f'Threshold used for adjusted predictions is: [ {round(0.5+0.005*best_ndx,2)} , {round(0.5-0.005*best_ndx,2)} ]')\n","  print('')\n","  print('Confusion matrix:')\n","  print(cm)\n","  print(classification_report(test_gen.classes, y_pred_adjusted, target_names= classes, digits= 4))\n","\n","  print(f'Change in accuracy           : {round((acc_list[best_ndx]-acc_list[0])*100,3)} %')\n","  print(f'Change in ALL precision      : {round((pre_list[best_ndx]-pre_list[0])*100,3)} %')\n","  print(f'Change in weighted precision : {round((w_pre_list[best_ndx]-w_pre_list[0])*100,3)} %')\n","  print(f'Change in ALL recall         : {round((rec_list[best_ndx]-rec_list[0])*100,3)} %')\n","  print(f'Change in weighted recall    : {round((w_rec_list[best_ndx]-w_rec_list[0])*100,3)} %')\n","  print(f'Change in ALL F1-score       : {round((f1_list[best_ndx]-f1_list[0])*100,3)} %')\n","  print(f'Change in weighted F1-score  : {round((w_f1_list[best_ndx]-w_f1_list[0])*100,3)} %')\n","  print()\n","\n","  best_scores.append(w_f1_list[best_w_f1_ndx]*100) # change here according to criteria\n","  y += 1"]},{"cell_type":"markdown","metadata":{"id":"SsIK5v0lGG69"},"source":["#### **Score results**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwnRlhGmJc08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691998516884,"user_tz":-480,"elapsed":5,"user":{"displayName":"Thesis TempF","userId":"15864590997921893499"}},"outputId":"b918ff05-49be-42c3-b8b1-c65dbe71dea1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Results (Weighted F1 Score comparison):\n","Model 1: 95.371 %\n","Model 2: 92.844 %\n","Model 3: 92.61 %\n","Model 4: 91.108 %\n","\n","Best result is Model 1 with score of 95.371 %\n"]}],"source":["print('Results (Weighted F1 Score comparison):')\n","for x in range(4):\n","  print(f'Model {x+1}: {round(best_scores[x],3)} %')\n","\n","print()\n","best_ndx = np.argmax(np.array(best_scores))\n","print(f'Best result is Model {best_ndx+1} with score of {round(best_scores[best_ndx],3)} %')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1U7q-vAMdSvn2RmUJjk3aVwq_AfJVeMbP","timestamp":1686480148075},{"file_id":"1aDJV89PWP52Aak-w2uLGmx0uaJurrSC_","timestamp":1686478574396},{"file_id":"1Wf4CH2uw1nuboyPkdVP7Icg-ukKQFXBs","timestamp":1686473318602},{"file_id":"1oCDoN9WYO78kgsbfZ3imy4YBWqO9C28b","timestamp":1686472576968},{"file_id":"1eHI97040KJdTXlR5-p7_4bsxsa3oNR0Q","timestamp":1686472455797},{"file_id":"1ZUvlGeenrQ59o_5E9FSmztakUmV7NX9C","timestamp":1686470694174},{"file_id":"1qIEHE2MNSh3xa_lmK1BpRLKaOg9s-Q-r","timestamp":1686470290860},{"file_id":"1OutGxyMN3vGgEQ43nDDdF5lwM1vGYleG","timestamp":1686469745176},{"file_id":"1BO4pwKJs8e-1bPMgTR5n9EPKiQy_7_2r","timestamp":1686468445519},{"file_id":"1MnRhe2mr_uT_5WVwwaAgUTIdo65HxkZN","timestamp":1686467452477},{"file_id":"16OdRqX8c14JpOI3fkhJOQdW7BKqzxzvW","timestamp":1686466531944}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"4e8b91188996e708824b56d4504145ad3b01498257cb32dbe996bd862d0a9b3b"}}},"nbformat":4,"nbformat_minor":0}